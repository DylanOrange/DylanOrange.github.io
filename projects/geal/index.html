<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GEAL: Generalizable 3D Affordance Learning with Cross-Modal Consistency</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://dylanorange.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://flexevent.github.io/">
            FlexEvent
          </a>
          <a class="navbar-item" href="https://yingyexin.github.io/simplemapping.html">
            SimpleMapping
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span style="color: rgb(70, 130, 180);">G</span><span style="color: rgb(123, 104, 238);">E</span><span style="color: rgb(138, 43, 226);">A</span><span style="color: rgb(75, 0, 130);">L</span>: Generalizable 3D Affordance Learning with Cross-Modal Consistency</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://dylanorange.github.io">Dongyue Lu</a>,</span>
            <span class="author-block">
              <a href="https://ldkong.com">Lingdong Kong</a>,</span>
            <span class="author-block">
              <a href="https://tianxinhuang.github.io/">Tianxin Huang</a>,</span>
            <span class="author-block">
              <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">National University of Singapore</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://dylanorange.github.io/projects/geal/static/files/geal.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2412.06708"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/DylanOrange/geal"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/dylanorange/geal"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
      <div style="text-align: center; margin-bottom: 20px;">
        <img src="static/files/top_webpage.jpg" alt="Top Image" style="width: 60%; max-width: 1000px; height: auto;">
      </div>
      <video autoplay muted loop playsinline style="max-width: none; height: auto; width: 1200px; margin-bottom: -10px;">
        <source src="static/videos/webpage.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <div style="display: flex; justify-content: space-between; width: 1200px; margin-bottom: 10px; text-align: center; font-weight: bold; font-size: 12px;">
        <div style="flex: 1; text-align: center;">Clean</div>
        <div style="flex: 1; text-align: center;">Rotate</div>
        <div style="flex: 1; text-align: center;">Jitter</div>
        <div style="flex: 1; text-align: center;">Scale</div>
        <div style="flex: 1; text-align: center;">Add Local</div>
        <div style="flex: 1; text-align: center;">Add Global</div>
        <div style="flex: 1; text-align: center;">Drop Local</div>
        <div style="flex: 1; text-align: center;">Drop Global</div>
      </div>   
      <h2 class="subtitle has-text-centered" style="margin-top: 20px;">
      <span style="color: rgb(70, 130, 180); font-weight: bold;">G</span><span style="color: rgb(123, 104, 238); font-weight: bold;">E</span><span style="color: rgb(138, 43, 226); font-weight: bold;">A</span><span style="color: rgb(75, 0, 130); font-weight: bold;">L</span> (bottom row), 
      demonstrates superior generalization and robustness across various data noise levels compared to the previous method (top row), based on a given text prompt.
      </h2>
    </div>
  </div>
</section>




<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Identifying affordance regions on 3D objects from semantic cues is essential for robotics and human-machine interaction. 
            However, existing 3D affordance learning methods struggle with generalization and robustness due to limited annotated data 
            and a reliance on 3D backbones focused on geometric encoding, which often lack resilience to real-world noise and data corruption. 
          </p>
          <p>
            We propose <span style="color: rgb(70, 130, 180); font-weight: bold;">G</span><span style="color: rgb(123, 104, 238); font-weight: bold;">E</span><span style="color: rgb(138, 43, 226); font-weight: bold;">A</span><span style="color: rgb(75, 0, 130); font-weight: bold;">L</span>, 
            a novel framework designed to enhance the generalization and robustness of 3D affordance learning by leveraging large-scale pre-trained 2D models. 
            We employ a dual-branch architecture with Gaussian splatting to establish consistent mappings between 3D point clouds and 2D representations, 
            enabling realistic 2D renderings from sparse point clouds. 
            A granularity-adaptive fusion module and a 2D-3D consistency alignment module further strengthen cross-modal alignment and knowledge transfer, 
            allowing the 3D branch to benefit from the rich semantics and generalization capacity of 2D models. 
          </p>
          <p>
            To holistically assess the robustness, 
            we introduce two new corruption-based benchmarks: PIAD-C and LASO-C. 
            Extensive experiments on public datasets and our benchmarks show that GEAL consistently outperforms existing methods across seen and novel object categories, 
            as well as corrupted data, demonstrating robust and adaptable affordance prediction under diverse conditions.
          </p>     
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method Section -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            Our proposed <span style="color: rgb(70, 130, 180); font-weight: bold;">G</span><span style="color: rgb(123, 104, 238); font-weight: bold;">E</span><span style="color: rgb(138, 43, 226); font-weight: bold;">A</span><span style="color: rgb(75, 0, 130); font-weight: bold;">L</span> 
            framework consists of two branches: 3D and 2D. 
            The 2D branch is established through 3D Gaussian Splatting to leverage the generalization capabilities of large pre-trained 2D models. 
            We then perform cross-modality alignment, including <strong>Granularity-Adaptive Visual-Textual Fusion</strong> and <strong>2D-3D Consistency Alignment</strong>, 
            to unify features from different modalities into a shared embedding space. 
            Finally, we decode generalizable affordance from this embedding space.
          </p>
        </div>
        <div class="content has-text-centered">
          <figure>
            <img src="static/files/single_framework.jpg" alt="Framework Diagram" style="max-width: 100%; height: auto; margin-bottom: 30px; width: 1000px;">
            <!-- <figcaption>Figure 1: Overview of the proposed method framework.</figcaption> -->
          </figure>
        </div>
      <!-- Submodules Section -->
      <div class="columns">
        <!-- Submodule 1 -->
        <div class="column">
          <p style="text-align: left; margin-bottom: 15px;">
            The <strong>2D-3D Consistency Alignment Module</strong> maps features from 2D and 3D modalities into a shared embedding space and enforces consistency alignment to enable effective knowledge transfer across branches.
          </p>
          <div>
            <figure>
              <img src="static/files/CA_module.jpg" alt="2D-3D Consistency Alignment Module" style="max-width: 100%; height: 340px; object-fit: cover;">
            </figure>
          </div>
        </div>
        <!-- Submodule 2 -->
        <div class="column">
          <p style="text-align: left; margin-bottom: 40px;">
            The <strong>Granularity-Adaptive Fusion Module</strong> consists of a Flexible Granularity Feature Aggregation mechanism (a) and a Text-Conditioned Visual Alignment mechanism (b).
          </p>
          <div>
            <figure>
              <img src="static/files/GAFM.jpg" alt="Granularity-Adaptive Fusion Module" style="max-width: 100%; height: 340px; object-fit: cover;">
            </figure>
          </div>
        </div>
      </div>

      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Experiment Table -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparisons to State-of-the-Art Methods</h2>
        <div class="content has-text-justified">
        <p>
          We compare <span style="color: rgb(70, 130, 180); font-weight: bold;">G</span><span style="color: rgb(123, 104, 238); font-weight: bold;">E</span><span style="color: rgb(138, 43, 226); font-weight: bold;">A</span><span style="color: rgb(75, 0, 130); font-weight: bold;">L</span> 
          with state-of-the-art 3D affordance learning methods on the PIAD and LASO dataset. Our method demonstrates strong generalization on both seen and unseen objects.
        </p>
      </div>
        <figure style="margin-top: 10px; text-align: center;">
          <img src="static/files/webpage_seen.jpg" alt="Framework Diagram" style="max-width: 100%; height: auto; width: 900px;">
        </figure>
        
      </div>
    </div>
  </div>
</section>

<section class="section"></section>
  <div class="container is-max-desktop">
    <!-- Experiment Section -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Corrupted Data Dataset</h2>
        <div class="content has-text-justified">
          <p>
            We establish two corruption-based benchmarks: PIAD-C and LASO-C, 
            to holistically evaluate the robustness of 3D affordance learning under real-world scenarios. We apply seven types of corruptions
             -- Add Global, Add Local, Drop Global, Drop Local, 
             Rotate, Scale, and Jitter -- each with five severity levels.
          </p>
        </div>
        <figure style="margin-top: 10px; text-align: center;">
          <img src="static/files/supp_benchmark_1.jpg" alt="Framework Diagram" style="max-width: 100%; height: auto; width: 1000px;">
        </figure>
        <figure style="margin-top: 40px; text-align: center; margin-bottom: 40px; ">
          <img src="static/files/supp_benchmark_2.jpg" alt="Framework Diagram" style="max-width: 100%; height: auto; width: 1000px;">
        </figure>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Experiment Section -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Generalization on Corrupted Data</h2>
        <div class="content has-text-justified">
          <p>
            We compare <span style="color: rgb(70, 130, 180); font-weight: bold;">G</span><span style="color: rgb(123, 104, 238); font-weight: bold;">E</span><span style="color: rgb(138, 43, 226); font-weight: bold;">A</span><span style="color: rgb(75, 0, 130); font-weight: bold;">L</span> 
          with state-of-the-art 3D affordance learning methods on the proposed PIAD-C and LASO-C corruption dataset. Our method maintains strong generalization and robustness across these challenging scenarios.
          </p>
        </div>
        <figure style="margin-top: 10px; text-align: center;">
          <img src="static/files/supp_corrupt_webpage.jpg" alt="Framework Diagram" style="max-width: 100%; height: auto; width: 1000px;">
        </figure>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{lu2024flexeventeventcameraobject,
      title={FlexEvent: Event Camera Object Detection at Arbitrary Frequencies}, 
      author={Dongyue Lu and Lingdong Kong and Gim Hee Lee and Camille Simon Chane and Wei Tsang Ooi},
      year={2024},
      eprint={2412.06708},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.06708}, 
}}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://dylanorange.github.io/projects/geal/static/files/geal.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/DylanOrange/geal" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. This webpage template is from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank the author of Nerfies for developing and open-sourcing this template. 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
